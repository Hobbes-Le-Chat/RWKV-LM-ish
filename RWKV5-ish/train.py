########################################################################################################
# The RWKV Language Model - https://github.com/BlinkDL/RWKV-LM
########################################################################################################

import logging
logging.basicConfig(level=logging.INFO)

if __name__ == "__main__":
    from argparse import ArgumentParser
    from pytorch_lightning import Trainer
    from pytorch_lightning.utilities import rank_zero_info, rank_zero_only
    import pytorch_lightning as pl
    from parser_for_train import get_train_args, update_args_for_mypile
    rank_zero_info("########## work in progress ##########")

    
    parser = get_train_args()

        # If using PyTorch Lightning version 2
    if not pl.__version__[0] == '2':
        parser = Trainer.add_argparse_args(parser)

    args = parser.parse_args()
    print(args)
    ########################################################################################################
    #rank_zero_only
    #def creating_dir(args)
    def update_args_for_rank_zero(args):
        if not os.path.exists(args.proj_dir):
            os.makedirs(args.proj_dir)

        if args.my_pile_stage > 0:
            magic_prime_bak = args.magic_prime

            if args.my_pile_shift < 0:
                args.my_pile_shift = 0

            if magic_prime_bak > 0:
                args.magic_prime = magic_prime_bak
            if args.my_qa_mask == 2:
                args.epoch_count = 2 * args.magic_prime // 40320
            else:
                args.epoch_count = args.magic_prime // 40320

            args.epoch_steps = 40320 // args.real_bsz
            assert args.epoch_steps * args.real_bsz == 40320
            
            if args.my_pile_stage >= 2:  # find latest saved model
                list_p = []
                for p in os.listdir(args.proj_dir):
                    if p.startswith("rwkv") and p.endswith(".pth"):
                        p = ((p.split("-"))[1].split("."))[0]
                        if p != "final":
                            if p == "init":
                                p = -1
                            else:
                                p = int(p)
                            list_p += [p]
                list_p.sort()
                max_p = list_p[-1]
                if len(list_p) > 1:
                    args.my_pile_prev_p = list_p[-2]  # in case max_p is corrupted
                if max_p == -1:
                    args.load_model = f"{args.proj_dir}/rwkv-init.pth"
                else:
                    args.load_model = f"{args.proj_dir}/rwkv-{max_p}.pth"
                    if args.warmup_steps < 0:
                        if args.my_pile_stage == 2:
                            args.warmup_steps = 10
                        else:
                            args.warmup_steps = 30
                args.epoch_begin = max_p + 1

        return args    

    ######################################################################################################################

    import os, warnings, math, datetime, sys, time
    import numpy as np
    import torch
    from torch.utils.data import DataLoader
    if "deepspeed" in args.strategy:
        import deepspeed
    from pytorch_lightning import seed_everything

    if args.random_seed >= 0:
        print(f"########## WARNING: GLOBAL SEED {args.random_seed} THIS WILL AFFECT MULTIGPU SAMPLING ##########\n" * 3)
        seed_everything(args.random_seed)

    np.set_printoptions(precision=4, suppress=True, linewidth=200)
    warnings.filterwarnings("ignore", ".*Consider increasing the value of the `num_workers` argument*")
    warnings.filterwarnings("ignore", ".*The progress bar already tracks a metric with the*")
    # os.environ["WDS_SHOW_SEED"] = "1"

    args.my_timestamp = datetime.datetime.today().strftime("%Y-%m-%d-%H-%M-%S")
    args.enable_checkpointing = False
    args.replace_sampler_ddp = False
    args.logger = False
    args.gradient_clip_val = 1.0
    args.num_sanity_val_steps = 0
    args.check_val_every_n_epoch = int(1e20)
    args.log_every_n_steps = int(1e20)
    args.max_epochs = -1  # continue forever
    args.betas = (args.beta1, args.beta2)
    args.real_bsz = int(args.num_nodes) * int(args.devices) * args.micro_bsz
    os.environ["RWKV_MY_TESTING"] = args.my_testing
    os.environ["RWKV_HEAD_SIZE_A"] = str(args.head_size_a)
    if args.dim_att <= 0:
        args.dim_att = args.n_embd
    if args.dim_ffn <= 0:
        args.dim_ffn = int((args.n_embd * 3.5) // 32 * 32) # default = 3.5x emb size

    if args.data_type == "wds_img":
        args.run_name = f"v{args.my_img_version}-{args.my_img_size}-{args.my_img_bit}bit-{args.my_img_clip}x{args.my_img_clip_scale}"
        args.proj_dir = f"{args.proj_dir}-{args.run_name}"
    else:
        args.run_name = f"{args.vocab_size} ctx{args.ctx_len} L{args.n_layer} D{args.n_embd}"
    if not os.path.exists(args.proj_dir):
        print(f"Creating project directory at: {args.proj_dir}")
        os.makedirs(args.proj_dir)

#    if args.my_pile_stage > 0:
#        magic_prime_bak = args.magic_prime

#        if args.my_pile_shift < 0:
#            args.my_pile_shift = 0

#        if magic_prime_bak > 0:
#            args.magic_prime = magic_prime_bak
#        if args.my_qa_mask == 2:
#            args.epoch_count = 2 * args.magic_prime // 40320
#        else:
#            args.epoch_count = args.magic_prime // 40320

#        args.epoch_steps = 40320 // args.real_bsz
#        assert args.epoch_steps * args.real_bsz == 40320
#        # if args.my_pile_stage == 2:
#        #     assert args.lr_final == args.lr_init
#        if args.my_pile_stage >= 2 and os.path.isdir(args.proj_dir) and os.listdir(args.proj_dir):
#        #if args.my_pile_stage >= 2:  # find latest saved model
#            list_p = []
#            for p in os.listdir(args.proj_dir):
#                if p.startswith("rwkv") and p.endswith(".pth"):
#                    p = ((p.split("-"))[1].split("."))[0]
#                    if p != "final":
#                        if p == "init":
#                            p = -1
#                        else:
#                            p = int(p)
#                        list_p += [p]
#            list_p.sort()
#            max_p = list_p[-1]
#            if len(list_p) > 1:
#                args.my_pile_prev_p = list_p[-2]  # in case max_p is corrupted
#            if max_p == -1:
#                args.load_model = f"{args.proj_dir}/rwkv-init.pth"
#            else:
#                args.load_model = f"{args.proj_dir}/rwkv-{max_p}.pth"
#                if args.warmup_steps < 0:
#                    if args.my_pile_stage == 2:
#                        args.warmup_steps = 10
#                    else:
#                        args.warmup_steps = 30
#            args.epoch_begin = max_p + 1
    args = update_args_for_mypile(args)
    if hasattr(args, 'epoch_steps') and hasattr(args, 'real_bsz'):
        samples_per_epoch = args.epoch_steps * args.real_bsz
        tokens_per_epoch = samples_per_epoch * args.ctx_len

    #samples_per_epoch = args.epoch_steps * args.real_bsz
    #tokens_per_epoch = samples_per_epoch * args.ctx_len
    try:
        deepspeed_version = deepspeed.__version__
    except:
        deepspeed_version = None
        pass
    rank_zero_info(
        f"""
############################################################################
#
# RWKV-5 {args.precision.upper()} on {args.num_nodes}x{args.devices} {args.accelerator.upper()}, bsz {args.num_nodes}x{args.devices}x{args.micro_bsz}={args.real_bsz}, {args.strategy} {'with grad_cp' if args.grad_cp > 0 else ''}
#
# Data = {args.data_file} ({args.data_type}), ProjDir = {args.proj_dir}
#
# Epoch = {args.epoch_begin} to {args.epoch_begin + args.epoch_count - 1} (will continue afterwards), save every {args.epoch_save} epoch
#
# Each "epoch" = {args.epoch_steps} steps, {samples_per_epoch} samples, {tokens_per_epoch} tokens
#
# Model = {args.n_layer} n_layer, {args.n_embd} n_embd, {args.ctx_len} ctx_len
#
# Adam = lr {args.lr_init} to {args.lr_final}, warmup {args.warmup_steps} steps, beta {args.betas}, eps {args.adam_eps}
#
# Found torch {torch.__version__}, recommend 1.13.1+cu117 or newer
# Found deepspeed {deepspeed_version}, recommend 0.7.0 (faster than newer versions)
# Found pytorch_lightning {pl.__version__}, recommend 1.9.5
#
############################################################################
"""
    )
    rank_zero_info(str(vars(args)) + "\n")

    assert args.data_type in ["utf-8", "utf-16le", "numpy", "binidx", "dummy", "uint16"]

    if args.lr_final == 0 or args.lr_init == 0:
        rank_zero_info("\n\nNote: lr_final = 0 or lr_init = 0. Using linear LR schedule instead.\n\n")

    assert args.precision in ["fp32", "tf32", "fp16", "bf16"]
    os.environ["RWKV_FLOAT_MODE"] = args.precision
    if args.precision == "fp32":
        for i in range(10):
            rank_zero_info("\n\nNote: you are using fp32 (very slow). Try bf16 / tf32 for faster training.\n\n")
    if args.precision == "fp16":
        rank_zero_info("\n\nNote: you are using fp16 (might overflow). Try bf16 / tf32 for stable training.\n\n")

    os.environ["RWKV_JIT_ON"] = "1"
    if "deepspeed_stage_3" in args.strategy:
        os.environ["RWKV_JIT_ON"] = "0"

    torch.backends.cudnn.benchmark = True
    torch.backends.cudnn.enabled = True
    if args.precision == "fp32":
        torch.backends.cudnn.allow_tf32 = False
        torch.backends.cuda.matmul.allow_tf32 = False
    else:
        torch.backends.cudnn.allow_tf32 = True
        torch.backends.cuda.matmul.allow_tf32 = True

    if "32" in args.precision:
        args.precision = 32
    elif args.precision == "fp16":
        args.precision = 16
    else:
        args.precision = "bf16"

    ########################################################################################################

    from src.trainer import train_callback, generate_init_weight
    from src.dataset import MyDataset
    from lightning.pytorch.callbacks import DeviceStatsMonitor
    from lightning.pytorch.profilers import AdvancedProfiler
    train_data = MyDataset(args)
    args.vocab_size = train_data.vocab_size

    from src.model import RWKV
    model = RWKV(args)

    if len(args.load_model) == 0 or args.my_pile_stage == 1:  # shall we build the initial weights?
        init_weight_name = f"{args.proj_dir}/rwkv-init.pth"
        generate_init_weight(model, init_weight_name)  # save initial weights
        args.load_model = init_weight_name

    rank_zero_info(f"########## Loading {args.load_model}... ##########")
    load_dict = None
    try:
        load_dict = torch.load(args.load_model, map_location="cpu")
        load_keys = list(load_dict.keys())
        for k in load_keys:
            if k.startswith('_forward_module.'):
                load_dict[k.replace('_forward_module.','')] = load_dict[k]
                del load_dict[k]
    except:
        rank_zero_info(f"Bad checkpoint {args.load_model}")
        if args.my_pile_stage >= 2:  # try again using another checkpoint
            max_p = args.my_pile_prev_p
            if max_p == -1:
                args.load_model = f"{args.proj_dir}/rwkv-init.pth"
            else:
                args.load_model = f"{args.proj_dir}/rwkv-{max_p}.pth"
            args.epoch_begin = max_p + 1
            rank_zero_info(f"Trying {args.load_model}")
            load_dict = torch.load(args.load_model, map_location="cpu")

    if args.load_partial == 1:
        load_keys = load_dict.keys()
        for k in model.state_dict():
            if k not in load_keys:
                load_dict[k] = model.state_dict()[k]
    if load_dict is not None:
        model.load_state_dict(load_dict)
    profiler = AdvancedProfiler(dirpath=args.proj_dir, filename="perf_logs")
    trainer = Trainer(profiler=profiler)
    if pl.__version__[0]=='2':
        trainer = Trainer(accelerator=args.accelerator,strategy=args.strategy,devices=args.devices,num_nodes=args.num_nodes,precision=args.precision,
        logger=args.logger,callbacks=[train_callback(args)],max_epochs=args.max_epochs,check_val_every_n_epoch=args.check_val_every_n_epoch,num_sanity_val_steps=args.num_sanity_val_steps,
        log_every_n_steps=args.log_every_n_steps,enable_checkpointing=args.enable_checkpointing,accumulate_grad_batches=args.accumulate_grad_batches,gradient_clip_val=args.gradient_clip_val)
    else:
        trainer = Trainer.from_argparse_args(
            args,
            callbacks=[train_callback(args)],profiler=profiler,
        )

    if trainer.global_rank == 0:
        for n in model.state_dict():
            shape = model.state_dict()[n].shape
            shape = [i for i in shape if i != 1]
            if len(shape) > 1:
                print(f"{str(shape[0]).ljust(5)} {str(shape[1]).ljust(5)} {n}")
            else:
                print(f"{str(shape[0]).ljust(5)}       {n}")

    if "deepspeed" in args.strategy:
        trainer.strategy.config["zero_optimization"]["allgather_bucket_size"] = args.ds_bucket_mb * 1000 * 1000
        trainer.strategy.config["zero_optimization"]["reduce_bucket_size"] = args.ds_bucket_mb * 1000 * 1000

    # must set shuffle=False, persistent_workers=False (because worker is in another thread)
    data_loader = DataLoader(train_data, shuffle=False, pin_memory=True, batch_size=args.micro_bsz, num_workers=1, persistent_workers=False, drop_last=True)

    trainer.fit(model, data_loader)
